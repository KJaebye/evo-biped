[32m[20230209 04:22:29 @logger.py:106][0m Log file set to ./tmp/evo_bipedalwalker/easy/20230209_042229/log/evo_bipedalwalker_easy-20230209_042229.log
[32m[20230209 04:22:29 @agent_ppo2.py:128][0m #------------------------ Iteration 0 --------------------------#
[32m[20230209 04:22:30 @agent_ppo2.py:134][0m Sampling time: 0.71 s by 1 slaves
[32m[20230209 04:22:30 @agent_ppo2.py:168][0m |      policy_loss |       value_loss |          entropy |
[32m[20230209 04:22:30 @agent_ppo2.py:193][0m |           0.0002 |         466.4523 |           0.0645 |
[32m[20230209 04:22:30 @agent_ppo2.py:193][0m |          -0.0035 |         455.2249 |           0.0645 |
[32m[20230209 04:22:30 @agent_ppo2.py:193][0m |           0.0041 |         454.6450 |           0.0645 |
[32m[20230209 04:22:30 @agent_ppo2.py:193][0m |           0.0084 |         441.8938 |           0.0645 |
[32m[20230209 04:22:30 @agent_ppo2.py:193][0m |          -0.0070 |         399.3430 |           0.0645 |
[32m[20230209 04:22:30 @agent_ppo2.py:193][0m |          -0.0045 |         386.8918 |           0.0645 |
[32m[20230209 04:22:30 @agent_ppo2.py:193][0m |          -0.0023 |         381.7136 |           0.0645 |
[32m[20230209 04:22:30 @agent_ppo2.py:193][0m |           0.0028 |         379.0391 |           0.0645 |
[32m[20230209 04:22:31 @agent_ppo2.py:193][0m |          -0.0024 |         362.1874 |           0.0645 |
[32m[20230209 04:22:31 @agent_ppo2.py:193][0m |          -0.0034 |         354.9101 |           0.0645 |
[32m[20230209 04:22:31 @agent_ppo2.py:137][0m Policy update time: 0.68 s
[32m[20230209 04:22:31 @agent_ppo2.py:145][0m Average TRAINING episode reward: -121.56
[32m[20230209 04:22:31 @agent_ppo2.py:146][0m Maximum TRAINING episode reward: -98.71
[32m[20230209 04:22:31 @agent_ppo2.py:147][0m Average EVALUATION episode reward: -91.73
[32m[20230209 04:22:31 @evo_bipedalwalker_agent.py:112][0m [4m[34mCRITICAL[0m Get the best episode reward: -91.73
[32m[20230209 04:22:31 @evo_bipedalwalker_agent.py:116][0m [4m[34mCRITICAL[0m Saving the best checkpoint with rewards -91.73
[32m[20230209 04:22:31 @agent_ppo2.py:150][0m Total time:       0.04 min
[32m[20230209 04:22:31 @agent_ppo2.py:152][0m 2048 total steps have happened
[32m[20230209 04:22:31 @agent_ppo2.py:128][0m #------------------------ Iteration 1 --------------------------#
